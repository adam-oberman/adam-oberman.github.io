# MATH/COMP 562: Theory of Machine Learning, Winter 2023
### Honours Mathematics for Machine Learning

Professor: Adam Oberman https://www.adamoberman.net/

Teaching Assistant: Viet Nguyen baviet.nguyen@mail.mcgill.ca

Class time: Tuesday and Thursday 2:35pm - 3:55 pm.  [Lea 14](https://maps.mcgill.ca/?cmp=1&txt=EN&id=Leacock)

Office Hours: TBD, and by appointment.

Lecture notes and assignments:  https://adam-oberman.github.io/  

Assigment submission: https://mycourses2.mcgill.ca/ 

----
[First Day Handout 2023 MATHCOMP 562.pdf](https://github.com/adam-oberman/adam-oberman.github.io/files/10360709/First.Day.Handout.2023.MATHCOMP.562.pdf)


##### Course Description

A mathematically rigorous approach to Machine Learning (ML), with a focus on a rigourous presentation of ML models.  Proofs of in-distribution generalization bounds.  

##### Audience 

- Math and Stats and theory oriented Computer Science graduate students.  
- Advanced undergraduate students who have prior background in implementing Machine Learning methods, and who plan to go on to graduate school. 

Students will be expected to have seen and coded ML models before. Experience with mathematical proofs and with probability is expected. 

### **Textbook**:

Learning Theory from First Principles, (January 1, 2023 edition)  [Free PDF](https://www.di.ens.fr/%7Efbach/ltfp_book.pdf),  by [Francis Bach](https://www.di.ens.fr/~fbach/)

#### Additional references

- [Mathematics for Machine Learning by Diesenroth](https://mml-book.github.io/) Review of prerequisites, with a ML focus.
- [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) by Shalev-Shwartz and Ben David  
- [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/) by Mohri, Rostamizadeh, Talwalkar. 

Use Shalev-Shwartz for introduction and definitions.  Use Mohri for the proofs, which are more precise. 

- [High dimensional statistics, a non-asymptotic viewpoint](https://people.eecs.berkeley.edu/~wainwrig/) by Martin J Wainwright. Advanced book on concentation of measure topics in machine learning.  The first chapters are a good source of advanced material on concentration of measure.  However, this material is covered in Bach Ch 1.  

### Project

Instructions [MathComp 562 Project Description.pdf](https://github.com/adam-oberman/adam-oberman.github.io/files/10354909/MathComp.562.Project.Description.pdf)
Suggested topics (old version) [Suggested Paper Links.pdf](https://github.com/adam-oberman/adam-oberman.github.io/files/10354935/Suggested.Paper.Links.pdf)

### Lectures

 - 01/05/2023 Zoom lecture, covered first day handout and projects.  Overview of Ch 2 of Bach: understanding "all you need is scale" vs. No Free Lunch Theorem.
 - 01/10/2023 In class.  Ch 2 Bach [Lecture 1 2023.01.10 562.pdf](https://github.com/adam-oberman/adam-oberman.github.io/files/10386101/Lecture.1.2023.01.10.562.pdf)
 - 01/12/2023 Thursday.  Cheat Sheet for Measure Theory/Probability/ML Notation.  PAC Learning, reference: Mohri Ch2, SS 2.3.1 & Ch 3.  [Lecture 3 2022.01.12.pdf](https://github.com/adam-oberman/adam-oberman.github.io/files/10438119/Lecture.3.2022.01.12.pdf)

Future Lectures:  
 - Chapter 3 of Mohri textbook. 
 - High Dimensional Probability  Reference: Jeff Calder Notes: [Calder Probability.pdf](https://github.com/adam-oberman/adam-oberman.github.io/files/10451272/Calder.Probability.pdf)
 - Proof of concentration of measure results. Hoeffding Ineq.  Reference: [Jeff Calder](https://www-users.cse.umn.edu/~jwcalder/) notes: [Calder Concetration of measure.pdf](https://github.com/adam-oberman/adam-oberman.github.io/files/10451268/Calder.Concetration.of.measure.pdf)


 
