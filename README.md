# MATH/COMP 562: Theory of Machine Learning
- Winter 2021, Adam Oberman https://www.adamoberman.net/
- Audience: Math and Stats Majors/Honours students, CS students.
### Prerequisites
Prerequisites: MATH 462 or COMP 451 or (COMP 551, MATH 222, MATH 223 and MATH 324) or ECSE 551.
### Related Courses
- Math 462, Fall 2021
  - To make sure that we all have the same background, there will be some overlap with this course in the first few weeks of term (of the 80+ students in 562, under 20 took 452).   Students from 462 can start their projet, and be excused from the small number of HW problems which overlap.
- COMP 551 Applied Machine Learning https://www.siamak.page/courses/COMP551F21/index.html
  - This course focuses on implementation, rather than theory.  This a complementary course.
- COMP 451 Fundamentals of Machine Learning  https://cs.mcgill.ca/~wlh/comp451/ (not recently offered)

### Main Textbook/References
- Notes from Math 462 (linked page)
- NLP Book https://mitpress.mit.edu/books/introduction-natural-language-processing
- Deep Learning book  https://www.deeplearningbook.org/
- RL Book http://www.incompleteideas.net/book/the-book-2nd.html
### Additional references
- [Mathematics for Machine Learning by Diesenroth](https://mml-book.github.io/) This book is elementary, but can be used as a reference or review of topics from the prerequisites
- [Probabilistic Machine Learning: An Introduction by Kevin Patrick Murphy](https://probml.github.io/pml-book/book1.html) This book is encyclopedic, covers many topics, good reference, but not presented as digestible lectures
- [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) by Shalev-Shwartz and Ben David  This book is very good for presenting machine learning problems, but less detailed on the proofs and part 3.
- [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/) by Mohri, Rostamizadeh, Talwalkar. This book contains rigorous proofs of generalization bounds, but assumes the reader is already familiar with the problems.
- [High dimensional statistics, a non-asymptotic viewpoint](https://people.eecs.berkeley.edu/~wainwrig/) by Martin J Wainwright.  Extra material on concetration of measure in the first chapters. 

## Grading (TBD)
- 5 HW assignments : 25%
- Group Project and Presentation: 15%
- Attendance 5%, Participation 5%.
- 2 Midterm Exams : 20%
- Final exam : 30%
- *Soft grading policy:* you are encouraged to make your best effort to complete all the work.  However, if you need to miss anything (assignment or exam), I will institute a soft grading policy which will allow one missed assignment and one missed midterm exam, with a small penalty.  Your final grade will be given by your average on the other work, with a penalty of:
  -   1% (for each assignment missed),
  -   2% (for a missed midterm).   
  -   3% (for a missed final exam)

E.g. if you missed one assignment and one midterm, with an average of 87% on the rest, then the penalty would be 87-(1+2) = 84%.  

## Key Dates (TBD)
Refer to [McGill key Dates](https://www.mcgill.ca/importantdates/key-dates#Fall_2021)
- Classes begin: Weds Sept 1.
- Fall reading break: Tues-Weds Oct. 12-13
- Makeup day: Oct 15, no class.  
- Last class: Friday Dec 3rd.
- Midterm dates: TBD
