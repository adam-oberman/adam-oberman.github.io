# MATH 462: Mathematics for Machine Learning
- Instructor: Adam Oberman
- Fall 2021

A mathematically rigorous approach to machine learning.

## Audience
Math and Stats Majors/Honours students, CS students.

## Prerequisites
- Math 223/Math 248 or equivalent (linear algebra majors/honours)
- Math 222 (Calculus 3)
- Math 324/Math 357 (Statistics)
- Probability course (implied, since it is a prerequisite for 324/357)
- Math 358 Honours Vector Calculus/Math 314 Advanced Calculus

## Related Courses

- Math 562, Winter 2022
  - This is a sequel to Math 462.  There will be a small amount of repetition of topics, since some students will not have taken 462.  However, to avoid repeated material, students from 462 will work on their project and be excused from HW problems which overlap.
- COMP 551 Applied Machine Learning https://www.siamak.page/courses/COMP551F21/index.html
  - This course focuses on implementation, rather than theory.  This a complementary course.
- COMP 451 Fundamentals of Machine Learning  https://cs.mcgill.ca/~wlh/comp451/
  - CS theory course, not currently offered.  Math 452 and Comp 451 are mutually exclusive.
- Math 308 Fundamentals of Statistical Learning
  - not offered this year.

## Textbook/References

-   [Mathematics for Machine Learning by Diesenroth](https://mml-book.github.io/) This book is elementary, but can be used as a reference or review of topics from the prerequisites
-   [Probabilistic Machine Learning: An Introduction by Kevin Patrick Murphy](https://probml.github.io/pml-book/book1.html) This book is encyclopedic, covers many topics, good reference, but not presented as digestible lectures
-   [Understanding Machine Learning: From Theory to Algorithms](https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/) by Shalev-Shwartz and Ben David  This book is very good for presenting machine learning problems, but less detailed on the proofs and part 3.
-   [Foundations of Machine Learning](https://cs.nyu.edu/~mohri/mlbook/) by Mohri, Rostamizadeh, Talwalkar. This book contains rigorous proofs of generalization bounds, but assumes the reader is already familiar with the problems.
-   [High dimensional statistics, a non-asymptotic viewpoint](https://people.eecs.berkeley.edu/~wainwrig/) by Martin J Wainwright.

## Grading
- 5 HW assignments : 25%
- Group Project and Presentation: 15%
- Attendance 5%, Participation 5%.
- 2 Midterm Exams : 20%
- Final exam : 30%
- *Soft grading policy:* you are encouraged to make your best effort to complete all the work.  However, if you need to miss anything (assignment or exam), I will institute a soft grading policy which will allow one missed assignment and one missed midterm exam, with a small penalty.  Your final grade will be given by your average on the other work, with a penalty of:
  -   1% (for each assignment missed),
  -   2% (for a missed midterm).   
  -   3% (for a missed final exam)

E.g. if you missed one assignment and one midterm, with an average of 87% on the rest, then the penalty would be 87-(1+2) = 84%.  

## Key Dates
Refer to [McGill key Dates](https://www.mcgill.ca/importantdates/key-dates#Fall_2021)
- Classes begin: Weds Sept 1.
- Fall reading break: Tues-Weds Oct. 12-13
- Makeup day: Oct 15, no class.  
- Last class: Friday Dec 3rd.
- Midterm dates: TBD
